---
pdf_document:
  citation_package: natbib
  fig_caption: yes
  keep_tex: yes
  latex_engine: pdflatex
  template: svm-latex-ms.tex
author:
- affiliation:
  - walker@maine.edu
  - Department of Biological Sciences, University of Southern Maine, 70 Falmouth Street,
    Portland, ME 04103
  name: Jeffrey A. Walker
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
fontfamily: mathpazo
fontsize: 11pt
geometry: margin=1in
bibliography: biblio.bib
title: Combining data, distribution summary, model effects, and uncertainty in a single
  plot
preprint: no
shorttitle: Harrell Plots
abstract: A Harrell plot combines a forest plot of estimated treatment effects and
  uncertainty, a dot plot of raw data, and a box plot of the distribution of the raw
  data into a single plot. A Harrell plot encourages best practices such as exploration
  of the distribution of the data and focus on effect size and uncertainty, while
  discouraging bad practices such as ignoring distributions and focusing on $p$-values.
  Consequently, a Harrell plot should replace the bar plots and Cleveland dot plots
  that are currently ubiquitous in the literature.
---

```{r setup, warning=FALSE, echo=FALSE, message=FALSE}
knitr::opts_knit$set(root.dir = getwd()) #echo=FALSE has to be set in each R chunk?

# Scripts for Harrell Plot.
# these are taken from HarrellPlot Shiny app working 15 (March 23, 2018)
# these are compiled in the HarrellPlot package

library(gridExtra) # needed for download
library(ggplot2)
library(cowplot)
library(broom)
library(lme4)
library(lmerTest)
library(lsmeans)
library(car)
library(data.table)
library(Hmisc) # smean.cl.boot
library(mvtnorm)

make_formula_str <- function(y, xcols=NULL, rintcols=NULL, rslopecols=NULL, icols=NULL, covcols=NULL){
  # xcols = fixed
  # rcols = random
  # icols = interaction
  
  # fixed effects
  form_str <- paste(y, ' ~ ', paste(c(covcols, xcols), collapse=' + '), sep='')
  # fixed interaction effects
  if(!is.null(icols)){
    combos <- data.frame(t(combn(icols,2)))
    i_str <- paste(paste(combos[,1],combos[,2],sep=':'), collapse=' + ')
    form_str <- paste(form_str, i_str, sep=' + ')
  }
  # random intercepts and slopes
  if(!is.null(rintcols)){
    if(is.null(rslopecols)){slope_str <- '1'}else{slope_str <- rslopecols}
    r_str <- paste(paste('(', slope_str, '|', rintcols, ')', sep=''), collapse=' + ')
    form_str <- paste(form_str, r_str, sep=' + ')
  }
  return(form_str)
}



contrast.groups <- function(contrast_matrix, grouping, add_interaction){
  split1 <- data.frame(t(do.call("cbind", strsplit(as.character(contrast_matrix$contrast)," - "))))
  if(grouping == TRUE & add_interaction==TRUE){
    split2a <- data.frame(t(do.call("cbind", strsplit(as.character(split1$X1),","))))
    colnames(split2a) <- c('X1','G1')
    split2b <- data.frame(t(do.call("cbind", strsplit(as.character(split1$X2),","))))
    colnames(split2b) <- c('X2','G2')
    group_names <- data.table(split2a, split2b)
  }else{
    group_names <- data.table(split1)
  }
  return(group_names)
}

fit_model <- function(
  x,
  y,
  g,
  covcols=NULL,
  rintcols=NULL,
  rslopecols=NULL,
  dt,
  fit.model='lm', # lm, glm
  error='Normal', # normal, lognormal, logistic, poisson
  add_interaction=FALSE,
  interaction.group=FALSE,
  interaction.treatment=TRUE,
  mean_intervals.method='raw', # model for CI of mean
  conf.mean=0.95, # confidence level for CI of mean
  contrasts.method='trt.vs.ctrl1', # which contrasts to show
  contrasts.scaling='raw', 
  conf.contrast=0.95,
  adjust=FALSE
){
  if(g=='dummy_g'){
    xcols <- x
    grouping <- FALSE
  }else{
    xcols <- c(x,g)
    grouping <- TRUE
  }
  
  if(add_interaction==TRUE){
    icols <- c(x,g)
  }else{
    icols <- NULL
  }
  
  model_formula <- formula(make_formula_str(y, xcols, rintcols, rslopecols, icols, covcols))
  
  if(fit.model=='lm'){
    fit <- lm(model_formula, data=dt)
  }
  if(fit.model=='lmm'){
    fit <- lmer(model_formula, data=dt)
  }
  lsm <- lsmeans(fit, specs=xcols)
  
  # save global
  tables <- list(NULL)
  tables$fit <- fit
  tables$form_str <- model_formula
  tables$coeffs <- coefficients(summary(fit))
  tables$summary <- glance(fit)
  tables$summary.raw <- summary(fit)
  tables$means.raw <- lsm
  # anova tables
  if(fit.model=='lm'){
    tables$anova.1 <- anova(fit)
    tables$anova.2 <- Anova(fit, type='II')
    options(contrasts=c(unordered="contr.sum", ordered="contr.poly"))
    tables$anova.3 <- Anova(lm(model_formula, data=dt), type='III')
    options(contrasts=c(unordered="contr.treatment", ordered="contr.poly"))
  }
  if(fit.model=='lmm'){
    # tables$anova.3 <- Anova(lmer(model_formula, data=dt), type='III')
    tables$anova.1 <- anova(lmer(model_formula, data=dt), type=1)
    tables$anova.2 <- anova(lmer(model_formula, data=dt), type=2)
    tables$anova.3 <- anova(lmer(model_formula, data=dt), type=3)
  }
  
  
  #     Bayes model
  #  mad <- median(abs(dt[,y] - mean(dt[,y])))
  #  #dt[,y.mad:=y/mad]
  #  y.mad <- dt[,y]/mad
  #  fit.mcmc <- MCMCregress(y.mad ~ x, data=dt, b0 = 0, B0 = 0.1, c0=2, d0=0.11)
  #  post.lsm <- lsmeans(fit.mcmc, specs='x')
  # # dt <- dt[, .SD, .SDcols=c('x','y')] #drop y.mad because need to bind ci later
  
  # means intervals
  if(mean_intervals.method=='lm'){
    tables$means <- confint(lsm, level=conf.mean)
    ci_means <- data.table(tables$means) # mean intervals not adjusted
    ci_means <- ci_means[, .SD, .SDcols=c(xcols,'lsmean','lower.CL','upper.CL')]
  }
  if(mean_intervals.method=='raw'){
    conf.tail <- conf.mean + (1-conf.mean)/2
    tables$means <- dt[, .(
      mean=mean(get(y)),
      sem=sd(get(y))/sqrt(.N),
      lower=mean(get(y))-sd(get(y))/sqrt(.N)*qt(conf.tail,(.N-1)),
      upper=mean(get(y))+sd(get(y))/sqrt(.N)*qt(conf.tail,(.N-1))),
      by=xcols]
    ci_means <- tables$means[, .SD, .SDcols=c(xcols,'mean', 'lower','upper')]
  }
  if(mean_intervals.method=='boot'){
    dt_boot <- data.table(dt[, smean.cl.boot(get(y),conf.int=conf.mean), by=xcols])
    dt_boot[, tile:=c('a','lower','upper')]
    form <- formula(paste(paste(xcols,collapse='+'),'tile',sep='~'))
    ci_means <- dcast(dt_boot, form, value.var='V1') #**** change x+g to formula
  }
  # if(mean_intervals.method=='bayes'){
  #   conf.tail <- conf.mean + (1-conf.mean)/2
  #   res <- summary(as.mcmc(post.lsm), quantiles = c(0.5, (1-conf.tail), conf.tail))$quantiles*mad
  #   ci_means <- data.table(x=row.names(res),res)
  #   ci_means[, (x):=factor(substr(x,3,nchar(x)))]
  # }
  if(grouping==FALSE){
    ci_means[, (g):='dummy']
    setnames(ci_means, old=colnames(ci_means), new=c(x, y, 'lower', 'upper', g))
    ci_means <- ci_means[,.SD, .SDcols=c(x, g, y,'lower','upper')]
  }else{
    setnames(ci_means, old=colnames(ci_means), new=c(xcols, y, 'lower','upper'))
  }
  
  #     contrast intervals
  x_levels <- levels(dt[, get(x)]) # levels for means plot
  g_levels <- levels(dt[, get(g)])
  n_levels <- length(x_levels)
  n_groups <- length(g_levels)
  
  if(contrasts.method=='coefficients'){
    ci_diffs <- coefficients(summary(fit))
    
    # get rid of df column from lmer fit
    if(fit.model=='lmm'){
      ci_diffs <- ci_diffs[,-which(colnames(ci_diffs)=='df')]
    }
    
    x_names <- c(x_levels[-1], g_levels[-1])
    if(add_interaction==TRUE){
      temp <- expand.grid(x_levels[-1], g_levels[-1])
      x_names <- c(x_names, paste(temp$Var1, temp$Var2, sep=':'))
    }
    # confint
    ci_ci <- confint(fit, level=conf.contrast)[row.names(ci_diffs),]
    ci_diffs <- cbind(ci_diffs, ci_ci)
    tables$contrasts <- data.table(contrast=x_names, ci_diffs[-1,])
    ci_diffs <- data.table(contrast=x_names, g='dummy', ci_diffs[-1,])
    setnames(ci_diffs, old=colnames(ci_diffs), new = c('contrast', 'g', 'estimate', 'Std. Error', 't value', 'Pr(>|t|)', 'lower', 'upper'))
    ci_diffs <- ci_diffs[, .SD, .SDcols=c('contrast','g','estimate','lower','upper')]
    ci_diffs[, contrast:=factor(contrast, levels=x_names)]
  }
  if(contrasts.method!='coefficients'){
    ci.adjust <- 'none'
    if(adjust==TRUE){
      ci.adjust <- ifelse(contrasts.method=='trt.vs.ctrl1', 'dunnettx','tukey')
    }
    if(grouping==FALSE | add_interaction==TRUE){
      ci_diffs <- summary(contrast(lsm, method=contrasts.method), adjust=ci.adjust, level=conf.contrast, infer=c(TRUE,TRUE))
      tables$contrasts.raw <- ci_diffs
      if(grouping==TRUE & contrasts.method=='revpairwise'){ # subset into pairwise within each group
        # another method
        # fread(paste(as.character(ci_diffs$contras), collapse='\n'), sep='-')
        inc <- NULL
        split1 <- data.frame(t(do.call("cbind", strsplit(as.character(ci_diffs$contrast)," - "))))
        split2a <- data.frame(t(do.call("cbind", strsplit(as.character(split1$X1),","))))
        colnames(split2a) <- c('x1','g1')
        split2b <- data.frame(t(do.call("cbind", strsplit(as.character(split1$X2),","))))
        colnames(split2b) <- c('x2','g2')
        splits <- data.table(split2a, split2b)
        # splits[, x1:=as.character(x1)]
        # splits[, x2:=as.character(x2)]
        # splits[, g1:=as.character(g1)]
        # splits[, g2:=as.character(g2)]
        if(interaction.group==TRUE){
          inc <- c(inc, which(splits[,g1]==splits[,g2]))
        }
        if(interaction.treatment==TRUE){
          inc.x <- which(splits[,x1]==splits[,x2])
          t.x <- factor(splits[inc.x, x1], levels(dt[, get(x)]))
          inc <- c(inc, inc.x[order(t.x)])
        }
        ci_diffs <- ci_diffs[inc,]
      }
      tables$contrasts <- ci_diffs
      ci_diffs <- data.table(ci_diffs, g='dummy')
    }
    if(grouping==TRUE & add_interaction==FALSE){
      if(contrasts.method=='revpairwise'){
        p_levels <- n_levels*(n_levels-1)/2
        p_groups <- n_groups*(n_groups-1)/2
      }else{
        p_levels <- n_levels-1
        p_groups <- n_groups-1
      }
      diffs.x <- summary(contrast(lsm, method=contrasts.method, by=g), adjust=ci.adjust, level=conf.contrast, infer=c(TRUE,TRUE))
      ci_diffs.x <- data.table(diffs.x)[1:p_levels]
      setnames(ci_diffs.x, old=c(g), new='by')
      diffs.g <- summary(contrast(lsm, method=contrasts.method, by=x), adjust=ci.adjust, level=conf.contrast, infer=c(TRUE,TRUE))
      ci_diffs.g <- data.table(diffs.g)[1:p_groups]
      setnames(ci_diffs.g, old=c(x), new='by')
      # save to tables
      tables$contrasts.raw <- list(by_treatment=diffs.x, by_grouping=diffs.g)
      # combine
      ci_diffs <- data.table(NULL)
      if(interaction.treatment==TRUE){ci_diffs <- rbind(ci_diffs, ci_diffs.x)}
      if(interaction.group==TRUE){ci_diffs <- rbind(ci_diffs, ci_diffs.g)}
      tables$contrasts <- copy(ci_diffs)
      setnames(ci_diffs, old=c('by'), new='g')
      # ci_diffs.x[, g:='x']
      # ci_diffs.g[, g:='g']
    }
    ci_diffs <- ci_diffs[, .SD, .SDcols=c('contrast','g','estimate','lower.CL','upper.CL')]
  }
  if(fit.model=='bayes'){
    conf.tail <- conf.contrast + (1-conf.contrast)/2
    res <- summary(as.mcmc(contrast(post.lsm, method=contrasts.method)), quantiles = c(0.5, (1-conf.tail), conf.tail))$quantiles*mad
    ci_diffs <- data.table(x=row.names(res),res)
    ci_diffs[, x:=factor(substr(x,10,nchar(x)))]
  }
  
  # make sure factor order of ci_diffs is in order they appear in the table
  ci_diffs[, contrast:=factor(contrast, ci_diffs$contrast)]
  
  yscale <- 1 # default
  if(contrasts.scaling=='standardized'){
    yscale <- summary(fit)$sigma
    ci_diffs[, estimate:=estimate/yscale]
    ci_diffs[, lower.CL:=lower.CL/yscale]
    ci_diffs[, upper.CL:=upper.CL/yscale]
    
    # scale tables$contrasts
    tables$contrasts <- data.table(tables$contrasts)
    tables$contrasts[, estimate:=estimate/yscale]
    tables$contrasts[, SE:=SE/yscale]
    tables$contrasts[, lower.CL:=lower.CL/yscale]
    tables$contrasts[, upper.CL:=upper.CL/yscale]
  }
  if(contrasts.scaling=='percent'){
    scale.o <- ci_diffs[1, estimate]
    group_names <- contrast.groups(ci_diffs, grouping, add_interaction)
    x1 <- group_names[, X2]
    x2 <- ci_means[, get(x)]
    if(grouping==TRUE & add_interaction==FALSE){
      g1 <- group_names[, X1]
      g2 <- group_names[, X2]
      xmean <- ci_means[, .(mean=mean(get(y))), by=get(x)]
      gmean <- ci_means[, .(mean=mean(get(y))), by=get(g)]
      inc.g1.x <- na.omit(match(g1, xmean$get))
      inc.g2.x <- na.omit(match(g2, xmean$get))
      num.x <- xmean[inc.g1.x, mean]
      denom.x <- xmean[inc.g2.x, mean]
      inc.g1.g <- na.omit(match(g1, gmean$get))
      inc.g2.g <- na.omit(match(g2, gmean$get))
      num.g <- gmean[inc.g1.g, mean]
      denom.g <- gmean[inc.g2.g, mean]
      denom <- c(denom.x, denom.g)
    }else{
      if(grouping==TRUE & add_interaction==TRUE){
        x1 <- paste(x1, group_names[, G2])
        x2 <- paste(x2, ci_means[, get(g)])
      }
      inc <- match(x1, x2)
      denom <- ci_means[inc, get(y)]
    }
    ci_diffs[, estimate:=100*estimate/denom]
    ci_diffs[, lower.CL:=100*lower.CL/denom]
    ci_diffs[, upper.CL:=100*upper.CL/denom]
    
    # # rescale back to scale.o
    # yscale <- scale.o/ci_diffs[1, estimate]
    # ci_diffs[, estimate:=estimate*yscale]
    # ci_diffs[, lower.CL:=lower.CL*yscale]
    # ci_diffs[, upper.CL:=upper.CL*yscale]
    
    # scale tables$contrasts
    tables$contrasts <- data.table(tables$contrasts)
    tables$contrasts[, estimate:=100*estimate/denom]
    tables$contrasts[, SE:=100*SE/denom]
    tables$contrasts[, lower.CL:=100*lower.CL/denom]
    tables$contrasts[, upper.CL:=100*upper.CL/denom]
    
  }
  
  setnames(ci_diffs, old=colnames(ci_diffs), new=c(x, g, y,'lower','upper'))
  return(list(fit=fit, ci_means=ci_means, ci_diffs=ci_diffs, tables=tables, yscale=yscale))
}

HarrellPlot <- function(
  # function for Harrell or Horizontal dot plot after Harrell's Hmisc
  x,
  y,
  g='None',
  covcols=NULL,
  rintcols=NULL,
  rslopecols=NULL,
  data, # data frame or table
  fit.model='lm', # lm, glm
  error='Normal', # normal, lognormal, logistic, poisson
  add_interaction=FALSE,
  interaction.group=FALSE,
  interaction.treatment=TRUE,
  mean_intervals.method='raw', # model for CI of mean
  conf.mean=0.95, # confidence level for CI of mean
  contrasts.method='trt.vs.ctrl1', # which contrasts to show
  contrasts.scaling='raw', 
  conf.contrast=0.95,
  adjust=FALSE,
  show.contrasts=TRUE,
  show.treatments=TRUE,
  display.treatment='box',
  short=FALSE,
  show.mean=TRUE,
  show.dots=TRUE,
  zero=TRUE,
  horizontal=TRUE,
  color_palette='Greys',
  jtheme='minimal',
  rel_height=0, # relative height of contrast vs. treatment subplots
  y_label=NULL # user supplied lable for Y axis
){
  # subset data
  if(g == 'None'){
    xcols <- x
    grouping <- FALSE
    add_interaction <- FALSE
    interaction.group <- FALSE
  }else{
    xcols <- c(x,g)
    grouping <- TRUE
  }
  data <- data.table(data)
  dt <- data[, .SD, .SDcols=unique(c(xcols, y, rintcols, rslopecols, covcols))]
  dt <- na.omit(dt) # has to be after groups read in
  
  # add empty grouping variable column if grouping == FALSE to make subsequent code easier
  if(grouping == FALSE){
    g <- 'dummy_g'
    dt[, (g):='dummy']
  }
  
  # abbreviate levels if TRUE
  if(short==TRUE){
    dt[, (x):=abbreviate(get(x))]
    dt[, (g):=abbreviate(get(g))]
  }
  x_order <- dt[,.(i=min(.I)),by=get(x)][, get]
  dt[, (x):=factor(get(x), x_order)]
  g_order <- dt[,.(i=min(.I)),by=get(g)][, get]
  dt[, (g):=factor(get(g), g_order)]
  
  res <- fit_model(x, y, g, covcols, rintcols, rslopecols, dt, fit.model, error, add_interaction, interaction.group, interaction.treatment, mean_intervals.method, conf.mean, contrasts.method, contrasts.scaling, conf.contrast, adjust)
  
  ci_means <- res$ci_means
  ci_diffs <- res$ci_diffs
  tables <- res$tables
  
  # temp for debug
  # tables$contrasts <- ci_diffs
  
  # plot it
  base.size <- 18
  
  gg_contrasts <- NULL
  gg_treatments <- NULL
  if(show.contrasts == TRUE){
    gg_contrasts <- ggplot(data=ci_diffs, aes_string(x=x, y=y)) +
      
      # draw line at y=0 first
      
      # draw effects + CI
      geom_linerange(aes(ymin = lower, ymax = upper), color='black', size=2) +
      geom_point(size=3, color='white') +
      geom_point(size=2, color='black')
    
    # re-label Y
    if(contrasts.scaling=='raw'){contrast_axis_name <- 'Effect'}
    if(contrasts.scaling=='percent'){contrast_axis_name <- 'Percent Effect'}
    if(contrasts.scaling=='standardized'){contrast_axis_name <- 'Standardized Effect'}
    gg_contrasts <- gg_contrasts + ylab(contrast_axis_name)
    
    # re-label X
    contrast_txt <- ifelse(contrasts.method=='coefficients', 'Coefficient', 'Contrast')
    gg_contrasts <- gg_contrasts + xlab(contrast_txt)
    
    # set theme and gridlines first as background
    if(jtheme=='grey'){
      gg_contrasts <- gg_contrasts + theme_grey(base_size = base.size)
    }
    if(jtheme=='gray'){
      gg_contrasts <- gg_contrasts + theme_gray(base_size = base.size)
    }
    if(jtheme=='bw'){
      gg_contrasts <- gg_contrasts + theme_bw(base_size = base.size)
    }
    if(jtheme=='classic'){
      gg_contrasts <- gg_contrasts + theme_classic(base_size = base.size)
    }
    if(jtheme=='minimal'){
      gg_contrasts <- gg_contrasts + theme_minimal(base_size = base.size)
    }
    if(jtheme=='cowplot'){
      gg_contrasts <- gg_contrasts + theme_cowplot(font_size = base.size)
    }
    
    # include zero in axis?
    y_range <- range(pretty(c(ci_diffs[, lower], ci_diffs[, upper])))
    ylims <- y_range
    if(min(y_range) > 0){
      ylims <-c(0, max(y_range))
    }
    if(max(y_range) < 0){
      ylims <- c(min(y_range), 0)
    }
    
    if(horizontal==TRUE){
      gg_contrasts <- gg_contrasts +
        scale_y_continuous(position = "right") +
        theme(plot.margin = margin(0, 0, 0, 0, "cm"))
      if(zero==TRUE){
        gg_contrasts <- gg_contrasts + coord_flip(ylim=ylims)
      }else{
        gg_contrasts <- gg_contrasts + coord_flip()
      }
      
    }
    
  }    
  
  if(show.treatments == TRUE){
    gg_treatments <- ggplot(data=dt, aes_string(x=x, y=y))
    dodge_width <- 0.75
    
    # show box plot
    if(display.treatment=='box'){ # plot before dots
      if(show.dots==TRUE){outlier_color <- NA}else{outlier_color <- NULL}
      gg_treatments <- gg_treatments + geom_boxplot(data=dt, aes_string(fill=g), outlier.colour = outlier_color)
    }
    
    if(display.treatment=='ci'){
      gg_treatments <- gg_treatments + geom_linerange(data=ci_means, aes_string(ymin = 'lower', ymax = 'upper', group=g), size=2, position=position_dodge(dodge_width))
      gg_treatments <- gg_treatments + geom_point(data=ci_means, aes_string(x=x, y=y, shape=g), size=5, color='white', position=position_dodge(dodge_width))
      gg_treatments <- gg_treatments + geom_point(data=ci_means, aes_string(x=x, y=y, shape=g), size=3, color='black', position=position_dodge(dodge_width))
      gg_treatments
    }
    
    # show dots
    if(show.dots==TRUE){
      #gg_treatments <- gg_treatments + geom_jitter(aes_string(group=g), width=0.1, height = 0.0, size=1, alpha=0.5)
      if(is.null(rintcols)){
        gg_treatments <- gg_treatments + geom_point(aes_string(fill=g), size=1, alpha=0.5, position=position_jitterdodge())
      }else{
        gg_treatments <- gg_treatments + geom_point(aes_string(fill=g), size=1, alpha=0.5, position=position_jitterdodge())
        # gg_treatments <- ggplot(data=dt, aes_string(x=x, y=y))
        # gg_treatments <- gg_treatments + geom_boxplot(data=dt, aes_string(fill=g), outlier.colour = outlier_color)
        # gg_treatments <- gg_treatments + geom_line(aes(group=Time, color=ID), position=position_dodge(dodge_width))
        # gg_treatments
      }
    }
    
    # show mean
    if(show.mean==TRUE & display.treatment=='box'){
      dot_color <- ifelse(color_palette=='Greys','black','black')
      gg_treatments <- gg_treatments + geom_point(data=ci_means, aes_string(x=x, y=y, group=g), size=3, color='white', position=position_dodge(width=dodge_width))
      gg_treatments <- gg_treatments + geom_point(data=ci_means, aes_string(x=x, y=y, group=g), size=2, color=dot_color, position=position_dodge(width=dodge_width))
    }
    
    # set colors
    if(color_palette != 'ggplot'){
      gg_treatments <- gg_treatments + scale_color_brewer(palette = color_palette)
      gg_treatments <- gg_treatments + scale_fill_brewer(palette = color_palette)
    }
    
    # set theme and gridlines first as background
    if(jtheme=='grey'){
      gg_treatments <- gg_treatments + theme_grey(base_size = base.size)
    }
    if(jtheme=='gray'){
      gg_treatments <- gg_treatments + theme_gray(base_size = base.size)
    }
    if(jtheme=='bw'){
      gg_treatments <- gg_treatments + theme_bw(base_size = base.size)
    }
    if(jtheme=='classic'){
      gg_treatments <- gg_treatments + theme_classic(base_size = base.size)
    }
    if(jtheme=='minimal'){
      gg_treatments <- gg_treatments + theme_minimal(base_size = base.size)
    }
    if(jtheme=='cowplot'){
      gg_treatments <- gg_treatments + theme_cowplot(font_size = base.size)
    }
    
    legend_postion <- ifelse(grouping==TRUE,'bottom','none')
    gg_treatments <- gg_treatments +
      theme(plot.margin = margin(0, 0, 0, 0, "cm"), legend.position = legend_postion)
    
    if(horizontal==TRUE){
      gg_treatments <- gg_treatments +
        coord_flip()
    }
    
    if(!is.null(y_label)){
      gg_treatments <- gg_treatments + ylab(y_label)
    }
  }
  
  if(rel_height==0){
    ar <- nrow(ci_diffs)/nrow(ci_means)
  }else{
    ar <- rel_height
  }
  if(show.contrasts==TRUE & show.treatments==TRUE){
    gg <- plot_grid(gg_contrasts, gg_treatments, nrow=2, align = "v", rel_heights = c(1*ar, 1))
  }
  if(show.contrasts==TRUE & show.treatments==FALSE){
    gg <- gg_contrasts
  }
  if(show.contrasts==FALSE & show.treatments==TRUE){
    gg <- gg_treatments
  }
  
  return(list(gg=gg, gg_contrasts=gg_contrasts, gg_treatments=gg_treatments, tables=tables))
}

```

# Introduction {-}
Recommended best practices for the reporting of statistical results include 1) showing the raw data and/or distribution of data in plots [@Drummond_Show_2011; @Weissgerber_Bar_2015; @Spitzer_BoxPlotR_2014; @Krzywinski_Points_2014; @Harrell_Principles_2014; @Weissgerber_Transparent_2016] and focusing on 2) effect size and (3) uncertainty in effect estimates instead of $p$-values of null hypothesis tests [@Nakagawa_Effect_2007;  @Yoccoz_Use_1991; @Johnson_insignificance_1999; @Curran-Everett_Fundamental_1998]. By contrast, standard practice throughout experimental biology includes the reporting of ANOVA results in tables and treatment means and standard errors of the mean in plots. At best, ANOVA tables poorly communicate effect size and uncertainty. Effects and uncertainty can be inferred from plots of treatment means and standard errors only indirectly.

Here, I introduce the Harrell plot, a tool to communicate statistical results from experiments, or any analysis with categorical independent variables (ANOVA-like linear models). A Harrell plot combines 1) a dot plot to show individual values, 2) a box plot to show the distribution of the response within treatment groups, and 3) a forest plot of effect estimates and confidence intervals to show modeled effect sizes and uncertainty. The combination of the effects in the top part and distribution in the bottom part of a Harrell plot was inspired by Fig. 1.1 of @Harrell_Principles_2014. The Harrell plot is implemented as an online [HarrellPlot Shiny app](https://middleprofessor.shinyapps.io/HarrellPlot/) [@Walker_HarrellPlot_2017] for users with no or limited R experience, including undergraduate biology majors. An R package for users with some R experience is in development.

# Effect size and uncertainty {-}
By effect, or effect size, I mean the magnitude and direction of the difference in response to some treatment, or some combination of treatments. If the mean critical thermal minimum is 5.1 $^\circ$ C in the control group of flies and 5.8 $^\circ$ C in the treated group, then the effect is $5.8 ^\circ \textrm{C} - 5.1 \textrm{C} = +0.7 ^\circ \textrm{C}$. The non-intercept coefficients of a linear model are effects. Contrasts of a linear model are effects. A confidence interval of the effect is a measure of the uncertainty in the estimate.  A 95% confidence interval of the effect has a 95\% probability (in the sense of long-run frequency) of containing the true effect. This probability is a property of the population of intervals that could be computed using the same sampling and measuring procedure. It is not correct, without further assumptions, to state that there is a 95% probability that the true effect lies within the interval. However, if we have only weak prior beliefs about the possible values of the effect, then it is valid, though possibly misleading, to state that there is an approximately 95\% probability that the true effect lies in the interval [@Greenland_Living_2013; @Gelman_Values_2013]. Perhaps a more useful interpretation is that the interval contains the range of effects that are consistent with the data, in the sense that a $t$-test would not reject the null hypothesis of a difference between the estimate and any value within the interval (this interpretation does not imply anything about the true value).

While many experiments in biology are conducted with a proximate goal of discovering or confirming that an effect exists (that is, the effect is something other than zero), the ultimate goal of a research program should be to understand the biological (including clinical, behavioral, ecological or evolutionary) consequences of effects [@Yoccoz_Use_1991; @Curran-Everett_Fundamental_1998; @Nakagawa_Effect_2007; @Batterham_Making_2006]. These consequences are functions of effect magnitude and direction and, consequently, estimates of effect size and uncertainty are tools for these ultimate goals. By contrast, hypothesis testing and $p$-values are tools only for the more proximate goal of effect presence. Importantly, the discovery that an effect exists requires more than a $p$-value, including both replicate experiments and modified experiments that "probe their experimental systems in multiple, independent ways" [@Vaux_Research_2012; see also @Munafo_Robust_2018]. Probing is standard in much of cell and molecular biology [but see @KaelinJr_Publish_2017]. Replications are uncommon throughout most of experimental biology. It probably cannot be emphasized enough that finding statistically significant $p$-values is a very low-bar in experimental biology. All components of complex physiological systems are causally connected and perturbing any feature of a system will have some effect on everything, however small (this may not be true in a simplified experimental system with a minimal number of components). Consequently, Type I errors will not exist in complex systems and the concept of null-hypothesis testing becomes meaningless. Instead, researchers should be concerned with sign and magnitude errors [@Gelman_Power_2014] and with conditional dependencies.

```{r confidence, out.width = "100%", fig.cap="Magnitude based inference using confidence intervals", echo=FALSE}
# magnitude-based inference 
bs <- c(0.6, 0.8, 1) # biologically sig
am1 <- c(0.4, 0.8, 1.2) # ambiguous 1
am2 <- c(0.2, 0.4, 0.6) # ambiguous 2
ts <- c(0.1, 0.2, 0.3) # trivially small
dat <- rbind(ts, am2, am1, bs)
colnames(dat) <- c('lower','Effect','upper')
level_order <- c('trivial', 'ambiguous II', 'ambiguous I', 'consequential')
dt <- data.table(Interpretation=factor(level_order, level_order),dat)
gg <- ggplot(data=dt, aes(x=Interpretation, y=Effect)) +
  geom_linerange(aes(min=lower, max=upper)) +
  geom_point(color='white', size=4) +
  geom_point(color='black', size=2) +
  geom_hline(aes(yintercept=0.5), linetype='dashed') +
  annotate("text", x = 4.5, y = .2, label = "Trivial") +
  annotate("text", x = 4.5, y = 0.9, label = "Consequential") +
  coord_flip(ylim=c(-.05, 1.25)) +
  theme_minimal() +
  theme(axis.title.y = element_blank())
gg
```

Confidence intervals of effects can be (and are most often) used to infer "statistical significance". Statisticians have long advocated for the far more valuable use of a confidence interval as a tool to infer the sensitivity of an interpretation or conclusion to the data [@Tukey_Philosophy_1991]. Again, a confidence interval of an effect gives the range of parameter values that are consistent with the data [@Amrhein_earth_2017b]. Consequently, as evidence for a theory in academic biology or a decision in applied biology, the whole range of values within a confidence interval, and not just the mean or median, should be consistent with an interpretation or conclusion, otherwise the data are ambiguous (or "inconclusive", but this might suggest that the results from a single study could ever be "conclusive"). One scheme for implementing this strategy is "magnitude-based inference", summarized in figure \@ref(fig:confidence), which is a modification of figure 2 of [@Barker_Inference_2008], which itself is a corrected interpretation of figure 2 in [@Batterham_Making_2006] (of course, by merely creating a boundary between trivial and consequential effect size, this strategy encourages rather than discourages dichotomization).

```{r plot bits, echo=FALSE, eval=FALSE, warning=FALSE }
# note the plot has marking requiring post-R modification. These are the bits

fn <- '../data/fly_burst.txt' # for knit
fly <- fread(fn, stringsAsFactors = TRUE)

# re-order so that Cn-F is the ref for the THCplot function
setorder(fly, -Treatment, Sex)
fly[, Treatment:=factor(Treatment, c('CN', 'AA'))]

# bar plot
gg.bar <- ggplot(data=fly, aes(x=Treatment, y=Vburst, group=Sex, fill=Sex)) +
  stat_summary(fun.y=mean, geom='col', position = position_dodge(0.9), color='black') +
  stat_summary(fun.data = 'mean_se', geom = c('errorbar'), width = 0.2, position = position_dodge(0.9)) +
  theme_minimal() +
  xlab('Selection Treatment') +
  ylab('Burst speed (cm/s)') +
  scale_fill_brewer(palette = 'Greys')
# gg.bar

pd <- 0.4
gg.me <- ggplot(data=fly, aes(x=Treatment, y=Vburst, group=Sex, shape=Sex)) +
  stat_summary(fun.y=mean, geom="line", position = position_dodge(pd), color='darkGrey') +
  stat_summary(fun.data = 'mean_se', geom = c('errorbar'), width = 0.2, position = position_dodge(pd)) +
  stat_summary(fun.y=mean, geom='point', position = position_dodge(pd), color='white', size=4) +
  stat_summary(fun.y=mean, geom='point', position = position_dodge(pd), color='black', size=3) +
  theme_minimal() +
  xlab('Selection Treatment') +
  ylab('Burst speed (cm/s)') +
  scale_fill_brewer(palette = 'Greys')
# gg.me

res <- HarrellPlot(x='Treatment', y='Vburst', g='Sex', data=fly, add_interaction = TRUE, contrasts.method = "revpairwise", interaction.group = TRUE, y_label = ('Burst speed (cm/s)') )
gg.hdot <- res$gg 
# gg.hdot

#fn <- "../HarrellPlot/manuscript/output/fig1a,b.pdf" # for console
fn <- "../output/fig1a,b.pdf" # for console
pwidth <- 7
pheight <- 3
pdf(fn, width=pwidth, height=pheight, onefile = TRUE)
grid.arrange(gg.bar, gg.me, nrow=1, ncol=2) 
dev.off()

fn <- '../HarrellPlot/manuscript/output/fig1c.pdf'
fn <- "../output/fig1c.pdf" # for console
pwidth <- 7
pheight <- 5
pdf(fn, width=pwidth, height=pheight, onefile = TRUE)
grid.arrange(gg.hdot, nrow=1, ncol=1) 
dev.off()

# Add annotation with Intaglio

```

```{r plots, out.width = "100%", fig.cap = "Three methods for communicating results of an experiment. In the bar plot (A) and a Cleveland dot plot (B), the treatment effect is inferred by mentally computing the distance between treatment means. In the Harrell plot (C), the treatment effect is plotted in addition to the treatment means. Key: AA selected flies, CN control flies, F female, M male", echo=FALSE}

image_path <- "../figs/fig1.pdf"
knitr::include_graphics(image_path)
#knitr::include_graphics("view.pdf")
```

## Mean-and-error plots {-}
Figure \@ref(fig:plots)A and B illustrate two kinds of mean-and-error plot. The unpublished data are the maximum burst speed of *Drosophila melanogaster* individuals from two lines that have undergone selection in a compartmentalized wind tunnel and two control lines [@Marden_Aerial_1997; @Weber_Large_1996]. Maximum burst speed was measured on individual flies that were stimulated to take-off and fly against a wind of known speed in a wind tunnel. The mean response of a group is represented either by the height of the bar (A) or a point symbol (B). The error bar most commonly represents one standard error of the mean; a confidence interval is less common. Occasionally, the error bar represents one sample standard deviation. Bar-and-error plots are ubiquitous in experimental cell biology. Point-and-error plots (or Cleveland dot plots) are more common in animal physiology than in cell biology. Perhaps because of the ubiquity of bar plots in cell biology (including the pages of Science, Nature, and Cell), most criticism of mean-and-error plots focusses on bar plots, which are pejoratively called "dynamite", "plunger", or "antenna" plots.

Three, related criticisms of mean-and-error plots are [@Drummond_Show_2011; @Weissgerber_Bar_2015; @Rousselet_few_2016], first, they do not show the data, which is important because multiple distributions can produce the same mean and error. Second, mean-and-error plots typically fail to reflect the analyzed model. For example, almost all mean-and-SE plots illustrate standard errors computed independently in each group instead of pooled standard errors resulting from the model. Or, for clustered data (repeated measures, blocked designs) mean-and-error plots give no indication of this lack of independence. And, third, error bars based on the sample standard deviation or standard error of the mean are not easily interpretable, and suggest a false interpretation, if the underlying data are not approximately normal.

These criticisms and even the solutions (box plots or dot plots) do not address the elephant in the room -- mean-and-error plots only indirectly communicate what we often want to directly communicate: the effects of the experimental treatments and the uncertainty in these effects. In a mean-and-error plot, effects have to be mentally reconstructed by comparing the difference in the response between two groups (figure \@ref(fig:plots)A and B). This is relatively easy if there are few groups and if the differences are large relative to the scale of the response axis. In bar plots especially, differences can often be very small relative to the height of the bar and figure \@ref(fig:plots)A is a good example of this. Regardless, effect uncertainty is much harder to mentally reconstruct, because the proper interval is a function of a standard error that is itself a function of the distribution of error variance in multiple groups. Because the approximate end-points of a confidence interval of a difference is time-consuming to mentally construct, mean-and-error plots encourage focus on the presence/absence of an effect (and it's direction) instead of the magnitude of the effect, including the magnitude of the ends of the confidence interval.

## The Harrell plot {-}
The Harrell plot addresses all three recommended practices by combining a forest plot of treatment effects, a box plot, and a jittered dot plot, into a single plot (figure \@ref(fig:plots)C). Modeled effects are illustrated in the upper part of the plot using a dot symbol representing the effect estimate and horizontal bars representing the effect uncertainty. Here, the bars are 95\% confidence intervals but these could be credible intervals from a Bayesian analysis. Forest plots of effects with horizontal uncertainty intervals are common in analyses with multiple responses, in meta-analysis, and in the epidemiology literature. The illustrated effects can be the coefficients of the linear model or contrasts between treatment combinations. If contrasts, these can be comparisons with a reference (such as a control) or pairwise comparisons.

The raw data are shown in the lower part of the plot using jittered dots, clustered by group. The distribution of data in each group is also shown in the lower part of the plot using a box plot. The precise tool to show the data and distributions is flexible but jittered dots and box plot reflect the best practice for much of experimental biology. While some advocate the use of an error bar, the box plot is more informative than an interval based on the sample standard deviation (including the sample confidence interval). And, an interval based on the standard error of the mean (including a 95% confidence interval of the mean) is often not the uncertainty that we want to communicate (see *Effect size and uncertainty* above).

# How Harrell plots improve inference  {-}

## Harrell plots discourage asterisks and letters {-}

```{r flyBar, echo=FALSE, out.width="100%", fig.cap="Bar plot of fly data. Error bars are 1 SEM. Asterisks indicate level of significance of inference test."}
path <- '../data/' # for knit
# path <- 'manuscript/data/' # for console
fn <- paste(path, 'fly_burst.txt', sep='') # for knit
fly <- fread(fn, stringsAsFactors = TRUE)
fly[, Treatment:=factor(Treatment, c('CN', 'AA'))]
fly_lm <- lm(Vburst ~ Treatment*Sex, data=fly)
fly_lsm <- lsmeans(fly_lm, specs=c('Treatment', 'Sex'))
fly_contrasts <- summary(contrast(fly_lsm, method='revpairwise'), adjust='none')

pd <- 0.9
gg_bar <- ggplot(data=fly, aes(x=Treatment, y=Vburst, fill=Sex, group=Sex)) +
  stat_summary(fun.data = 'mean_se', geom = c('errorbar'), width = 0.2, position = position_dodge(pd)) +
  stat_summary(fun.y=mean, geom="col", position = position_dodge(pd), color='black') +
  scale_fill_manual(values=c("lightgray", "black")) +
  theme_minimal(base_size = 14) +
  ylab('Burst Speed (cm/s)') +
  coord_cartesian(ylim = c(0, 225)) +
  annotate("segment", x=1-.25, y=145, xend=1+.25, yend=145, size=2) +
  annotate("text", x=1, y=150, label=c('*'), size=14) +
  annotate("segment", x=1-.25, y=190, xend=2-.25, yend=190, size=2) +
  annotate("text", x=1.5-.25, y=195, label=c('***'), size=14) +
  annotate("segment", x=1+.25, y=210, xend=2+.25, yend=210, size=2) +
  annotate("text", x=1.5+.25, y=215, label=c('***'), size=14)

gg_bar
```

```{r make_flyHarrell, echo=FALSE, results='hide'}
# average standard error of raw group values
res <- HarrellPlot(x='Treatment', y='Vburst', g='Sex', data=fly, add_interaction = TRUE, interaction.group = TRUE, contrasts.method = 'revpairwise', contrasts.scaling = 'percent', y_label = ('Burst Speed (cm/s)'))
gg_hplot <- res$gg

path <- '../output/' # for knit
#path <- 'manuscript/output/' # for console
image_path <- paste(path, 'fly_Hplot.pdf', sep='') # for knit
pwidth <- 8
pheight <- 6
pdf(image_path, width=pwidth, height=pheight, onefile = TRUE)
grid.arrange(gg_hplot, nrow=1, ncol=1) 
dev.off()

# average SE difference
mean_sed <- mean(res$tables$contrasts[, SE])
```

```{r flyHarrell, echo=FALSE, out.width="90%", fig.cap="Harrell plot of fly linear model results. Error bars are 95\\% confidence intervals"}
path <- '../output/' # for knit
#path <- 'manuscript/output/' # for console
image_path <- paste(path, 'fly_Hplot.pdf', sep='') # for knit
knitr::include_graphics(image_path)

```

Figure \@ref(fig:flyBar) is a bar plot with 1 SE bar for the results of the *Drosophila* wind-tunnel selection experiment described above. The asterisks, which indicate statistically significant $p$-values for tests of specific contrasts, draw the researcher and reader into comparing means using the heights of the bars. The asterisks are helpful for this because the standard error bars are not especially helpful given the computations necessary to go from the illustrated SEMs to the relevant SEDs. But the asterisks encourage the researcher/reader into focussing on $p$-values of inferential tests, which should be discouraged instead. Even more egregiously, the asterisks encourage the researcher/reader to misinterpret the number of asterisks as effect size.

A Harrell plot (figure \@ref(fig:flyHarrell), by contrast, nudges researchers/readers to focus on modeled effect size and uncertainty instead of classification of results into "significant" and "non-significant" bins (or "highly significant" bins). Here, I've scaled the contrasts as percents, since I haven't given much thought to the biological consequences of a 50 cm/s increase in burst speed (in fact, percents discourage the hard work of understanding the biological consequences of effect size). Certainly, one can use the 95% confidence limits to mentally bin comparisons into significant and non-significant bins, but the plot itself does not encourage it. Instead, the plot encourages a researcher/reader to consider how the range of values in a CI support, or fail to support, different interpretations of the results. For example, the effects of the long term selection experiment is much larger than the effects of sex on burst speed. And, a model of males having smaller burst speed relative to females in both wind-tunnel selected (AA) and control (CN) flies is consistant with the data.

## Harrell plots explicitly show modeled treatment effects and uncertainty {-}

```{r mouseBarPlot, echo=FALSE, out.width="100%", fig.cap="Increase in body fat in the fake mouse data. (A) Percent increase. (B) Raw measures of body fat at baseline and at the end of the treatment period. Error bars are 1SE. "}
# from Bias in pre-post designs -- An example from the Turnbaugh et al (2006) mouse fecal transplant study -- Walker 2018

# create data.table of Turnbaugh mouse body fat data. Numbers are from paper.
mouse <- data.table(treatment = c('+/+', 'ob/ob'),
                    n = c(10, 9),
                    percent = c(.27, .47),
                    change = c(.86, 1.3),
                    se_percent = c(0.036, 0.083),
                    se_change = c(0.1, 0.2)
                    )
mouse[, init:=change/percent]
mouse[, final:=init+change]
mouse[, sd:=sqrt(se_change^2*n/2)] # sample sd, assume homogenous pre/post
# reorder columns
mouse <- mouse[, .SD, .SDcols=c('treatment', 'n', 'init', 'final', 'sd', 'change', 'percent', 'se_change', 'se_percent')]

# parameters for model
Sigma_ii <- mean(mouse[, sd^2]) # variances for both init and final
sigma <- sqrt(Sigma_ii) # standard deviations
rho <- 0.4 # pre-post correlation. I have no idea what the actual value is.
mu <- mean(mouse[, init]) # initial weight
delta <- mean(mouse[, change]) # delta is the post - pre effect for control
tau <- 0 # tau is the treatment effect (on top of delta)
Sigma <- matrix(c(c(Sigma_ii, rho*Sigma_ii), c(rho*Sigma_ii, Sigma_ii)), nrow=2)
N <- sum(mouse[, n])

seed <- 1673 # recovers stats
set.seed(seed)

# create pre-post mouse weights that are correlated
treatment <- rep(c('+/+','ob/ob'), mouse[,n])
weights <- rmvnorm(n=N, mean=c(mu, mu+delta), sigma=Sigma)
weights[treatment=='ob/ob', 2] <- weights[treatment=='ob/ob', 2] + tau
fake_mouse <- data.table(ID=factor(1:N),
                 treatment=factor(treatment, c('+/+','ob/ob')),
                 init=weights[,1],
                 final=weights[,2])
fake_mouse[, change:=final-init]
fake_mouse[, percent:=change/init*100]

path <- '../output/' # for knit
# path <- 'manuscript/output/' # for console
fout <- paste(path, 'fake_mouse.txt', sep='')
write.table(fake_mouse, fout, row.names=FALSE, quote=FALSE, sep='\t')

fake_mouse_long <- melt(fake_mouse, id.vars=c('ID', 'treatment'), measure.vars=c('init', 'final'), variable.name='Time', value.name='Weight')
fout <- paste(path, 'fake_mouse_long.txt', sep='')
write.table(fake_mouse_long, fout, row.names=FALSE, quote=FALSE, sep='\t')

fake_mouse_sum <- fake_mouse[, .(final=mean(final),
                 percent_change=mean(percent), 
                 se=sd(percent)/sqrt(.N), 
                 cs=mean(change), 
                 se.change=sd(change)/sqrt(.N)), 
             by=treatment]

# plot using bar plot of percent change
gg_bar <- ggplot(data=fake_mouse_sum, aes(x=treatment, y=percent_change, fill=treatment)) +
  geom_errorbar(aes(ymin=(percent_change-se), ymax=(percent_change+se)), width=.2) +
  geom_col(fill=c('white', 'black'), color='black') +
  ylab("Increase in Body Fat (%)") +
  xlab("Donor") +
  scale_y_continuous(limits=c(0,60)) +
  theme_minimal() +
  theme(legend.position='none')

# t.test(fake_mouse[treatment=='ob/ob',percent],
#       fake_mouse[treatment=='+/+',percent])

pd <- 0.4
gg_inter <- ggplot(data=fake_mouse_long, aes(x=Time, y=Weight, group=treatment, shape=treatment)) +
  stat_summary(fun.y=mean, geom="line", position = position_dodge(pd), color='darkGrey') +
  stat_summary(fun.data = 'mean_se', geom = c('errorbar'), width = 0.2, position = position_dodge(pd)) +
  stat_summary(fun.y=mean, geom='point', position = position_dodge(pd), color='white', size=4) +
  stat_summary(fun.y=mean, geom='point', position = position_dodge(pd), color='black', size=3) +
  theme_minimal() +
  ylab('Body fat (grams)') +
  scale_fill_brewer(palette = 'Greys')

# coefficients(summary(lm(Weight ~ treatment*Time, data=fake_mouse_long)))

plot_grid(gg_bar, gg_inter, labels = c("A", "B"), align = "h")

```

```{r mouseHarrellPlot, echo=FALSE, out.width="100%", fig.cap="A Harrell plot of the simulated mouse data. Effects are shown as a percent to be consistent with the original plot from Turnbaugh et al. 2006. The lower panel is a box plot of the percent change in body fat weights. The means are shown with the large dot with a white halo. The unconditional difference between these means is 22\\%, similar to that in the original data. The upper panel is the contrast between treatment levels -- the difference in percent weight change -- from the linear model with initial weight as a covariate. The error bar is a 95\\% confidence interval of this effect. This conditional effect is 3\\% and the confidence interval is consistent with both small negative and small positive effects."}
# plot using HarrellPlot
res <- HarrellPlot(x='treatment', y='percent', covcols='init', data=fake_mouse, y_label = ('Increase in Body Fat (%)'))
res$gg 
```

It is reasonably straightforward to reconstruct raw differences among groups from a mean-and-error plot, but a major advantage of a Harrell plot is the explicit display of modeled effects and uncertainty. This visual display of modeled effects makes inference from a plot consistent with inference from a statistical analysis summarized in a table or in the text. For example, @Turnbaugh_obesityassociated_2006a published a figure like that in figure \@ref(fig:mouseBarPlot)A, which compares the percent increase in body fat for mice colonized with microbes from feces from obese (*ob/ob*) mice and for mice colonized with microbes from feces from normal (+/+) mice. The data are simulated to mimic the summary statistics of those given in the original paper [@Turnbaugh_obesityassociated_2006a; see @Walker_Bias_2018]. Turnbaugh et al. inferred an effect from a simple $t$-test of these percent change scores. The relevant statistics are the difference in means and the standard error of this difference (SED). While it is easy to mentally reconstruct the difference in means from the bar plot, it is very hard to mentally reconstruct a very useful SED because it is a function of two standard errors of the mean (SEM) and because both SEMs are noticeably different for these data. The relevant effect and its error are even harder to infer from the plot of the raw pre-post means (figure \@ref(fig:mouseBarPlot)B), because the effect is the $Time \times Treatment$ interaction.

Inference of treatment effect in both analyses in figure (\@ref(fig:mouseBarPlot)A) (which would be the same if the analysis in A were on the raw change) suffer from regression to the mean [@Walker_Bias_2018]. To avoid this, a linear model including the initial body fat measure as a covariate should be used. The treatment effect is now conditional on the initial measure. Unfortunately, it is effectively impossible to mentally reconstruct a conditional effect like this from any plot of the raw (unconditional) means, regardless if using a bar plot, or a dot plot, or a box plot with superimposed means.

By combining a box/dot plot of the raw data and a forest plot of the modeled effect (figure \@ref(fig:mouseHarrellPlot), a Harrell plot shows both the raw data and distribution summary and a direct visualization of the estimated effect and uncertainty. The mouse data are particularly striking to demonstrate this because of the big difference between the direct inference from the upper panel and the indirect inference using the unconditional means in the bottom panel. 

# References {-}

